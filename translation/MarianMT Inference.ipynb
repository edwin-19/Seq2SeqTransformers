{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooperative-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.seq2seq import Seq2SeqModel\n",
    "import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dense-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mt/eng_-french.csv')\n",
    "df['English words/sentences'] = df['English words/sentences'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", ' ', x))\n",
    "df['French words/sentences'] = df['French words/sentences'].apply(lambda x: re.sub(r\"[^a-zA-Z0-9]+\", ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "curious-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel(\n",
    "    encoder_decoder_type='marian',\n",
    "    encoder_decoder_name='weights/outputs/best_model/',\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distributed-principle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2eb5742feb4c98b7746dd1a3e5e8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating outputs', max=1.0, style=ProgressStyle(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/superceed1/anaconda3/envs/py38torch17/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3277: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict(df['English words/sentences'].iloc[:10].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buried-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635f114b4e1048808f023fd03b6cbe7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2488.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric = datasets.load_metric('bleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "basic-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = df['English words/sentences'].tolist()\n",
    "french_text = df['French words/sentences'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rental-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng Text: Hi \n",
      "GT FR: salut \n",
      "Pred FR: bonjour\n",
      "\n",
      "Eng Text: Run \n",
      "GT FR: cours \n",
      "Pred FR: courez\n",
      "\n",
      "Eng Text: Run \n",
      "GT FR: courez \n",
      "Pred FR: courez\n",
      "\n",
      "Eng Text: Who \n",
      "GT FR: qui \n",
      "Pred FR: qui\n",
      "\n",
      "Eng Text: Wow \n",
      "GT FR:  a alors \n",
      "Pred FR: ouhau\n",
      "\n",
      "Eng Text: Fire \n",
      "GT FR: au feu \n",
      "Pred FR: feu\n",
      "\n",
      "Eng Text: Help \n",
      "GT FR:  l aide \n",
      "Pred FR: aide\n",
      "\n",
      "Eng Text: Jump \n",
      "GT FR: saute \n",
      "Pred FR: salue\n",
      "\n",
      "Eng Text: Stop \n",
      "GT FR:  a suffit \n",
      "Pred FR: arr te\n",
      "\n",
      "Eng Text: Stop \n",
      "GT FR: stop \n",
      "Pred FR: arr te\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eng_text, ori_fr_text, pred_fr_text in zip(english_text[:10], french_text[:10], outputs):\n",
    "    print('Eng Text: {}'.format(eng_text))\n",
    "    print('GT FR: {}'.format(ori_fr_text.lower()))\n",
    "    print('Pred FR: {}\\n'.format(pred_fr_text.lower()))\n",
    "    \n",
    "#     bleu = metric.compute(predictions=[pred_fr_text.lower().split()], references=[[ori_fr_text.lower().split()]])\n",
    "#     print('Bleu Score: {}\\n'.format(bleu['bleu']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
