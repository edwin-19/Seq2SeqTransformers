{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "import pytorch_lightning as pl\n",
    "import spacy\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-civilization",
   "metadata": {},
   "source": [
    "# Load model & tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "american-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.json', 'r') as file:\n",
    "    index_tag = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "existing-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes=38):\n",
    "        super(NerClassifier, self).__init__()\n",
    "        self.bert_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert_model(input_ids, attention_mask)\n",
    "        return self.classifier(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "known-parameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = NerClassifier()\n",
    "model.load_state_dict(torch.load('weights/ontotnote_model.pth'))\n",
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-steps",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adopted-silence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Today', 'B-DATE'],\n",
       " ['5th', 'B-ORDINAL'],\n",
       " ['the', 'I-DATE'],\n",
       " ['year', 'I-DATE']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Today is the 5th of the year 2020'\n",
    "sent = sentence.split(' ')\n",
    "\n",
    "tokenized_input = tokenizer(\n",
    "    [sent], is_split_into_words=True, return_offsets_mapping=True, padding='max_length', truncation=True,\n",
    "    return_tensors='pt', max_length=128\n",
    ")\n",
    "\n",
    "preds = model(tokenized_input['input_ids'].to('cuda'), tokenized_input['attention_mask'].to('cuda'))\n",
    "preds = preds.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "predictions = np.argmax(preds, axis=1)\n",
    "\n",
    "entities = []\n",
    "for index, pred in enumerate(predictions[:len(sentence.split(' '))]):\n",
    "    tag = index_tag[str(pred)]\n",
    "    if tag != 'O':\n",
    "        entities.append([sent[index - 1], tag])\n",
    "        \n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capable-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Date</span>\n",
       "</mark>\n",
       " is the 5th of the year 2020</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "doc = nlp(sentence)\n",
    "\n",
    "ents = []\n",
    "# for entity in entities:\n",
    "#     span_start ,span_end, label = entity\n",
    "ent = doc.char_span(0, 5, label='Date')\n",
    "# if ent is None:\n",
    "#     continue\n",
    "\n",
    "ents.append(ent)\n",
    "\n",
    "doc.ents = ents\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
