{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regulation-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler, RandomSampler\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seven-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-removal",
   "metadata": {},
   "source": [
    "# Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worldwide-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 4\n",
    "learning_rate = 2e-5\n",
    "eps = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-professor",
   "metadata": {},
   "source": [
    "# Load & preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fresh-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coqa-train-v1.0.json', 'r') as json_file:\n",
    "    data = json.loads(json_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seasonal-sponsorship",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "formatted_data = []\n",
    "for d in data['data']:\n",
    "    for ques, ans in zip(d['questions'], d['answers']):\n",
    "        formatted_data.append({\n",
    "            'id': d['id'],\n",
    "            'question': ques['input_text'],\n",
    "            'answer': ans,\n",
    "            'context': d['story'],\n",
    "            'source': d['source']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-subcommittee",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crazy-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=400, stride=128):\n",
    "        super(QADataset, self).__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.stride = stride\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        question = self.df['question'].iloc[index]\n",
    "        ans = self.df['answer'].iloc[index]\n",
    "        context = self.df['context'].iloc[index]\n",
    "        \n",
    "        tokenized_input = self.tokenizer(\n",
    "            question, context,\n",
    "            max_length=self.max_len, truncation=\"only_second\",\n",
    "            return_overflowing_tokens=True, return_offsets_mapping=True,\n",
    "            stride=self.stride, padding='max_length'\n",
    "        )\n",
    "        \n",
    "        start_position = []\n",
    "        end_position = []\n",
    "        for i, offsets in enumerate(tokenized_input['offset_mapping']):\n",
    "            input_ids = tokenized_input['input_ids'][i]\n",
    "            cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "            sequence_ids = tokenized_input.sequence_ids(i)\n",
    "\n",
    "            if ans['span_start'] == 0:\n",
    "                start_position.append(cls_index)\n",
    "                end_position.append(cls_index)\n",
    "            else:\n",
    "                start_char = ans['span_start']\n",
    "                end_char = ans['span_end']\n",
    "\n",
    "                token_start_idx = 0\n",
    "                while sequence_ids[token_start_idx] != 1:\n",
    "                    token_start_idx += 1\n",
    "\n",
    "                token_end_index = len(tokenized_input['input_ids']) - 1\n",
    "                while sequence_ids[token_end_index] != 1:\n",
    "                    token_end_index -= 1\n",
    "                if (offsets[token_start_idx][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                    while token_start_idx < len(offsets) and offsets[token_start_idx][0] <= start_char:\n",
    "                        token_start_idx += 1\n",
    "\n",
    "                    start_position.append(token_start_idx - 1)\n",
    "                    while offsets[token_end_index][1] >= end_char:\n",
    "                        token_end_index -= 1\n",
    "                    end_position.append(token_end_index + 1)\n",
    "                else:\n",
    "                    start_position.append(cls_index)\n",
    "                    end_position.append(cls_index)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(tokenized_input['input_ids'][0]),\n",
    "            'attention_mask': torch.tensor(tokenized_input['attention_mask'][0]),\n",
    "            'start_positions': torch.tensor(start_position[0]),\n",
    "            'end_positions': torch.tensor(end_position[0])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "correct-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(df, tokenizer)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-ecology",
   "metadata": {},
   "source": [
    "# Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reasonable-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-cased')\n",
    "model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proper-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=eps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=epochs * len(train_dataloader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-wrong",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respected-anthony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5bc154d9e141dea32aec12d2f894ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6845754c7b436aa12f7698f62e132c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13581.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Training Epoch 1]\n",
      "Training loss: 1.642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563b4adea6ee4ed0b2e651c138c6f8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13581.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Training Epoch 2]\n",
      "Training loss: 1.299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644ef6ca85a4899bad6ca81d9a9871e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13581.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Training Epoch 3]\n",
      "Training loss: 1.057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cac25ace3d845c081b128fa088d3669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13581.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Training Epoch 4]\n",
      "Training loss: 0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_training_loss = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, train_data in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        input_ids = train_data['input_ids'].to('cuda')\n",
    "        attention_mask = train_data['attention_mask'].to('cuda')\n",
    "        start_positions = train_data['start_positions'].to('cuda')\n",
    "        end_positions = train_data['end_positions'].to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        training_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print('[Training Epoch %d]\\nTraining loss: %.3f' %(epoch + 1, training_loss / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('weights'):\n",
    "    os.makedirs('weights')\n",
    "    \n",
    "model.save_pretrained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
