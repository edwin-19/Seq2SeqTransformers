{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "foster-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import orjson as json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-wheat",
   "metadata": {},
   "source": [
    "# Download and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "square-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_json('http://downloads.cs.stanford.edu/nlp/data/coqa/coqa-train-v1.0.json')\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sustained-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"text\",\"question\",\"answer\"]#list of lists to create our dataframe\n",
    "comp_list = []\n",
    "for row in coqa.itertuples():\n",
    "    for i in range(len(row.data[\"questions\"])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row.data[\"story\"])\n",
    "        temp_list.append(row.data[\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row.data[\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "\n",
    "optimized_df = pd.DataFrame(comp_list, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-witch",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "coupled-coordinate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "tested-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = optimized_df.sample(1)\n",
    "question = sample_df.iloc[0]['question']\n",
    "context = sample_df.iloc[0]['text']\n",
    "answer = sample_df.iloc[0]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "worth-debate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('7 January 1943',\n",
       " 'And died?',\n",
       " 'Nikola Tesla (Serbian Cyrillic: Никола Тесла; 10 July 1856 – 7 January 1943) was a Serbian American inventor, electrical engineer, mechanical engineer, physicist, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system. \\n\\nTesla gained experience in telephony and electrical engineering before emigrating to the United States in 1884 to work for Thomas Edison in New York City. He soon struck out on his own with financial backers, setting up laboratories and companies to develop a range of electrical devices. His patented AC induction motor and transformer were licensed by George Westinghouse, who also hired Tesla for a short time as a consultant. His work in the formative years of electric power development was involved in a corporate alternating current/direct current \"War of Currents\" as well as various patent battles. \\n\\nTesla went on to pursue his ideas of wireless lighting and electricity distribution in his high-voltage, high-frequency power experiments in New York and Colorado Springs, and made early (1893) pronouncements on the possibility of wireless communication with his devices. He tried to put these ideas to practical use in an ill-fated attempt at intercontinental wireless transmission, his unfinished Wardenclyffe Tower project. In his lab he also conducted a range of experiments with mechanical oscillators/generators, electrical discharge tubes, and early X-ray imaging. He also built a wireless controlled boat, one of the first ever exhibited.')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer, question, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "religious-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input = tokenizer.encode_plus(question, context, return_tensors='pt')\n",
    "outputs = model(**tokenized_input)\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "numeric-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7 January 1943) was a Serbian American'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[start_scores.argmax(axis=1):end_scores.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-industry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
